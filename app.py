import streamlit as st
import cv2
import numpy as np
import time
from streamlit_image_comparison import image_comparison

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(
    page_title="Ancient Doc Restore",
    page_icon="üìú",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS T√ôY CH·ªàNH (L√†m ƒë·∫πp giao di·ªán) ---
st.markdown("""
    <style>
        .main {
            background-color: #f5f5f5;
        }
        h1 {
            color: #4b2e2e;
            text-align: center;
        }
        .stButton>button {
            width: 100%;
            background-color: #ff4b4b;
            color: white;
        }
    </style>
""", unsafe_allow_html=True)

def render_sidebar():
    with st.sidebar:
        st.header("‚öôÔ∏è B·∫£ng ƒêi·ªÅu Khi·ªÉn")
        st.info("Tinh ch·ªânh c√°c th√¥ng s·ªë thu·∫≠t to√°n t·∫°i ƒë√¢y.")
        
        # Nh√≥m 1: Kh·ª≠ nhi·ªÖu (Denoiser)
        st.subheader("1. Kh·ª≠ Nhi·ªÖu (Denoise)")
        median_k = st.slider("Median Kernel (Di·ªát ƒë·ªëm)", 1, 7, 3, step=2, help="K√≠ch th∆∞·ªõc c·ª≠a s·ªï l·ªçc trung v·ªã. L·ªõn qu√° s·∫Ω m·∫•t n√©t nh·ªè.")
        gaussian_k = st.slider("Gaussian Kernel (M·ªãn n·ªÅn)", 1, 9, 3, step=2)
        
        # Nh√≥m 2: TƒÉng c∆∞·ªùng (Enhancer)
        st.subheader("2. TƒÉng C∆∞·ªùng (Enhance)")
        clip_limit = st.slider("CLAHE Clip Limit", 1.0, 5.0, 2.0, help="Gi·ªõi h·∫°n ƒë·ªô t∆∞∆°ng ph·∫£n c·ª•c b·ªô.")
        sharp_amount = st.slider("ƒê·ªô n√©t (Sharpen)", 0.0, 3.0, 1.0, help="C∆∞·ªùng ƒë·ªô l√†m n√©t Unsharp Mask.")

        # Nh√≥m 3: T√°ch ch·ªØ (Segmentation)
        st.subheader("3. T√°ch Ch·ªØ (Binarize)")
        sauvola_k = st.slider("Sauvola k-factor", 0.01, 0.5, 0.2, help="ƒê·ªô nh·∫°y c·ªßa ng∆∞·ª°ng t√°ch ch·ªØ.")

        st.markdown("---")
        st.caption("Nh√≥m th·ª±c hi·ªán: ")
        
        # Tr·∫£ v·ªÅ m·ªôt dictionary ch·ª©a c√°c tham s·ªë ƒë·ªÉ main d√πng
        return {
            "median_k": median_k,
            "gaussian_k": gaussian_k,
            "clip_limit": clip_limit,
            "sharp_amount": sharp_amount,
            "sauvola_k": sauvola_k
        }

def to_rgb(img):
    """convert m√†u cho ƒë√∫ng chu·∫©n hi·ªÉn th·ªã Web."""
    if img is None: return None
    if len(img.shape) == 2: return cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

def main():
    # --- HEADER ---
    st.title("üìú H·ªÜ TH·ªêNG PH·ª§C H·ªíI & S·ªê H√ìA T√ÄI LI·ªÜU C·ªî")
    st.markdown("---")

    params = render_sidebar()

    # --- MAIN AREA: INPUT & PROCESS ---
    col_upload, col_action = st.columns([3, 2])
    
    with col_upload:
        uploaded_file = st.file_uploader("üìÇ T·∫£i l√™n ·∫£nh t√†i li·ªáu (JPG, PNG)...", type=['jpg', 'png', 'jpeg'])

    # Session State ƒë·ªÉ l∆∞u k·∫øt qu·∫£ (tr√°nh m·∫•t khi reload trang)
    if 'results' not in st.session_state:
        st.session_state.results = None

    if uploaded_file is not None:
        # 1. ƒê·ªçc ·∫£nh v√†o b·ªô nh·ªõ
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        img_input = cv2.imdecode(file_bytes, 1) # BGR format

        # Hi·ªÉn th·ªã ·∫£nh g·ªëc
        with col_action:
            st.write("Preview ·∫¢nh G·ªëc:")
            st.image(to_rgb(img_input),use_container_width=True)
            
            # N√∫t ch·∫°y x·ª≠ l√Ω
            if st.button("üöÄ B·∫ÆT ƒê·∫¶U PH·ª§C H·ªíI", type="primary"):
                with st.spinner("ƒêang kh·ªüi ƒë·ªông Pipeline..."):
                    # --- CH·ªñ N√ÄY S·∫º G·ªåI PIPELINE C·ª¶A B·∫†N ---
                    # pipeline = DocumentRestorationPipeline()
                    # st.session_state.results = pipeline.run(img_input, params)
                    
                    # (Gi·∫£ l·∫≠p k·∫øt qu·∫£ ƒë·ªÉ test giao di·ªán khi ch∆∞a c√≥ pipeline)
                    time.sleep(1) # Gi·∫£ v·ªù ƒëang ch·∫°y
                    dummy_res = {
                        '1_Input': img_input,
			'2_Gauss':cv2.GaussianBlur(img_input, ksize = (5,5), sigmaX = 2),
                        '7_Final_Crop': cv2.bitwise_not(img_input) # Ngh·ªãch ƒë·∫£o m√†u l√†m v√≠ d·ª•
                    }
                    st.session_state.results = dummy_res
                
                st.success("X·ª≠ l√Ω ho√†n t·∫•t!")

    # --- K·∫æT QU·∫¢ (HI·ªÇN TH·ªä SAU KHI C√ì D·ªÆ LI·ªÜU) ---
    if st.session_state.results is not None:
        results = st.session_state.results
        
        st.markdown("### üìä K·∫æT QU·∫¢ X·ª¨ L√ù")
        
        # T·∫°o Tabs ch·ª©c nƒÉng
        tab_compare, tab_detail, tab_showcase, tab_export = st.tabs([
            "üîç So s√°nh Tr·ª±c quan", 
            "üõ†Ô∏è Gi·∫£i ph·∫´u Chi ti·∫øt", 
            "üé• Tr√¨nh di·ªÖn (Showcase)", 
            "üíæ Xu·∫•t b·∫£n"
        ])

        # === TAB 1: SO S√ÅNH (IMAGE COMPARISON) ===
        with tab_compare:
            st.markdown("#### So s√°nh Tr∆∞·ªõc & Sau")
            
            img_before = to_rgb(results.get('1_Input', img_input))
            img_after = to_rgb(results.get('Output_Visual', results.get('7_Final_Crop')))

            if img_before is not None and img_after is not None:
                image_comparison(
                    img1=img_before,
                    img2=img_after,
                    label1="·∫¢nh G·ªëc (Nhi·ªÖu/Cong)",
                    label2="K·∫øt Qu·∫£ (Ph·∫≥ng/S·∫°ch)",
                    width=700,
                    starting_position=50,
                    show_labels=True,
                    make_responsive=True,
                    in_memory=True
                )

        # === TAB 2: CHI TI·∫æT T·ª™NG B∆Ø·ªöC ===
        with tab_detail:
            st.markdown("#### C√°c b∆∞·ªõc trung gian trong Pipeline")
            # (B·∫°n c√≥ th·ªÉ th√™m code hi·ªÉn th·ªã c√°c b∆∞·ªõc trung gian ·ªü ƒë√¢y khi c√≥ pipeline th·ª±c)
            st.info("Ch∆∞a c√≥ d·ªØ li·ªáu chi ti·∫øt (C·∫ßn k·∫øt n·ªëi Pipeline).")

        # === TAB 3: TR√åNH DI·ªÑN (ANIMATION & SLIDESHOW) ===
        with tab_showcase:
            st.markdown("#### Xem l·∫°i qu√° tr√¨nh bi·∫øn ƒë·ªïi")
            
            col_anim_btn, col_anim_view = st.columns([1, 4])
            
            with col_anim_btn:
                run_anim = st.button("‚ñ∂Ô∏è Ch·∫°y Timelapse")
                st.info("B·∫•m n√∫t ƒë·ªÉ xem ·∫£nh bi·∫øn ƒë·ªïi t·ª´ t·ª´.")

            with col_anim_view:
                placeholder_img = st.empty()
                placeholder_txt = st.empty()
                progress_bar = st.empty()

                if run_anim:
                    # Danh s√°ch c√°c b∆∞·ªõc gi·∫£ l·∫≠p ƒë·ªÉ test giao di·ªán
                    steps = [
                        ("1. ·∫¢nh ƒê·∫ßu V√†o", results.get('1_Input')),
			("2. L√†m m·ªù", results.get('2_Gauss')),
                        ("‚úÖ HO√ÄN TH√ÄNH!", results.get('7_Final_Crop'))
                    ]

                    for i, (text, img_step) in enumerate(steps):
                        if img_step is not None:
                            placeholder_txt.markdown(f"**{text}**")
                            placeholder_img.image(to_rgb(img_step), use_container_width=True)
                            progress_bar.progress((i + 1) / len(steps))
                            time.sleep(1.0)
                    
                    st.balloons() 

        # === TAB 4: XU·∫§T B·∫¢N (DOWNLOAD) ===
        with tab_export:
            st.markdown("#### T·∫£i xu·ªëng K·∫øt qu·∫£")
            
            final_img = results.get('7_Final_Crop')
            
            if final_img is not None:
                is_success, buffer = cv2.imencode(".png", final_img)
                if is_success:
                    st.download_button(
                        label="üì• T·∫£i ·∫£nh PNG (Ch·∫•t l∆∞·ª£ng cao)",
                        data=buffer.tobytes(),
                        file_name="restored_document.png",
                        mime="image/png"
                    )

if __name__ == "__main__":
	main()
